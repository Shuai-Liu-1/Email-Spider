{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428dd82a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "This notebook shows how to create or use an email spider, also known as an email scraper or email extractor. It is \n",
    "    **important to note**\n",
    "    that using email spiders to scrape or extract email addresses from websites or databases without consent is often considered unethical and may be illegal in some jurisdictions. It is always recommended to obtain permission from the website or database owner before collecting email addresses. Additionally, sending unsolicited emails or spam is generally prohibited and can result in penalties and legal consequences.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.linkextractors.lxmlhtml import LxmlLinkExtractor\n",
    "from googlesearch import search\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "logging.getLogger('scrapy').propagate = False\n",
    "#avoid getting too many logs and warnings when using Scrapy inside Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(tag, n, language):\n",
    "    urls = [url for url in search(tag, stop=n, lang=language)][:n]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6356c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailSpider(scrapy.Spider):\n",
    "    \n",
    "    name = 'email'\n",
    "    \n",
    "#because in most websites contact information is not going to be found straight in the main page, \n",
    "    #but rather in a contact page or so. Therefore, in the first parse method weâ€™re running a link \n",
    "    #extractor object (LxmlLinkExtractor), \n",
    "    #that checks for new URLs inside a source\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        links = LxmlLinkExtractor(allow=()).extract_links(response)\n",
    "        links = [str(link.url) for link in links]\n",
    "        links.append(str(response.url))\n",
    "        \n",
    "        #the one responsible for sending links from one parse method to another. \n",
    "        #This is accomplished by a callback argument that defines to which method the\n",
    "        #request URL must be sent to.\n",
    "        \n",
    "        for link in links:\n",
    "            yield scrapy.Request(url=link, callback=self.parse_link) \n",
    "            \n",
    "    def parse_link(self, response):\n",
    "        \n",
    "        for word in self.reject:\n",
    "            if word in str(response.url):\n",
    "                return\n",
    "            \n",
    "        html_text = str(response.text)\n",
    "        \n",
    "        mail_list = re.findall('\\w+@\\w+\\.{1}\\w+', html_text)\n",
    "\n",
    "        dic = {'email': mail_list, 'link': str(response.url)}\n",
    "        df = pd.DataFrame(dic)\n",
    "        \n",
    "        df.to_csv(self.path, mode='a', header=False)\n",
    "        df.to_csv(self.path, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b79b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save those emails in a CSV file\n",
    "def ask_user(question):\n",
    "    response = input(question + ' y/n' + '\\n')\n",
    "    if response == 'y':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def create_file(path):\n",
    "    response = False\n",
    "    if os.path.exists(path):\n",
    "        response = ask_user('File already exists, replace?')\n",
    "        if response == False: return \n",
    "    \n",
    "    with open(path, 'wb') as file: \n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(tag, n, language, path, reject=[]):\n",
    "    \n",
    "    create_file(path)\n",
    "    df = pd.DataFrame(columns=['email', 'link'], index=[0])\n",
    "    df.to_csv(path, mode='w', header=True)\n",
    "    \n",
    "    print('Collecting Google urls...')\n",
    "    google_urls = get_urls(tag, n, language)\n",
    "    \n",
    "    print('Searching for emails...')\n",
    "    process = CrawlerProcess({'USER_AGENT': 'Mozilla/5.0'})\n",
    "    process.crawl(MailSpider, start_urls=google_urls, path=path, reject=reject)\n",
    "    process.start()\n",
    "    \n",
    "    print('Cleaning emails...')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df.columns = ['email', 'link']\n",
    "    df = df.drop_duplicates(subset='email')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(path, mode='w', header=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ca483",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = ['facebook', 'instagram', 'youtube', 'twitter', 'wiki']\n",
    "SearchWords=input(\"Please Enter Words You need to search for email or links: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246daabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_urls(SearchWords, 2, 'en')\n",
    "df = get_info(SearchWords, 2, 'en', 'k.csv')#, reject=bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42dd5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
